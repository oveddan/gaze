{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare list of features. \n",
    "\n",
    "We only have one numeric feature. There are many other types of columns that are more complicated and useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='x', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An estimator \n",
    "is the front end to invoke training (fitting) and evaluation (inference). There are many predefined types like linear regression, linear classification, and many neural network classifiers and regressors. The following code provides an estimator that does linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/9x/qdmf325n77sbk47cq7lthwjw0000gn/T/tmpaSUDjH\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x107c63e10>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/9x/qdmf325n77sbk47cq7lthwjw0000gn/T/tmpaSUDjH', '_save_summary_steps': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x1135647d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "Here we use two data sets: one for training and one for evaluation. We have to tell the function how many batches of data (num_epochs) we want and how big each batch should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function tensorflow.python.estimator.inputs.numpy_io.input_fn>,\n",
       " <function tensorflow.python.estimator.inputs.numpy_io.input_fn>,\n",
       " <function tensorflow.python.estimator.inputs.numpy_io.input_fn>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "input_fn, train_input_fn, eval_input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can invoke 1000 training steps\n",
    "by invoking the  method and passing the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/9x/qdmf325n77sbk47cq7lthwjw0000gn/T/tmpaSUDjH/model.ckpt-2000\n",
      "INFO:tensorflow:Saving checkpoints for 2001 into /var/folders/9x/qdmf325n77sbk47cq7lthwjw0000gn/T/tmpaSUDjH/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.28253e-12, step = 2001\n",
      "INFO:tensorflow:global_step/sec: 665.358\n",
      "INFO:tensorflow:loss = 2.29505e-12, step = 2101 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 739.7\n",
      "INFO:tensorflow:loss = 6.96332e-13, step = 2201 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 788.394\n",
      "INFO:tensorflow:loss = 1.49569e-12, step = 2301 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 846.64\n",
      "INFO:tensorflow:loss = 6.82121e-13, step = 2401 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.168\n",
      "INFO:tensorflow:loss = 1.36424e-12, step = 2501 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.056\n",
      "INFO:tensorflow:loss = 1.36424e-12, step = 2601 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 722.058\n",
      "INFO:tensorflow:loss = 1.1795e-12, step = 2701 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 777.248\n",
      "INFO:tensorflow:loss = 6.11067e-13, step = 2801 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.262\n",
      "INFO:tensorflow:loss = 6.96332e-13, step = 2901 (0.128 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /var/folders/9x/qdmf325n77sbk47cq7lthwjw0000gn/T/tmpaSUDjH/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.21689e-12.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x1135647d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=input_fn, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we evaluate how well our model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-11-05-20:25:16\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/9x/qdmf325n77sbk47cq7lthwjw0000gn/T/tmpaSUDjH/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-05-20:25:17\n",
      "INFO:tensorflow:Saving dict for global step 3000: average_loss = 2.66454e-13, global_step = 3000, loss = 1.06581e-12\n",
      "INFO:tensorflow:Starting evaluation at 2017-11-05-20:25:17\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/9x/qdmf325n77sbk47cq7lthwjw0000gn/T/tmpaSUDjH/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2017-11-05-20:25:18\n",
      "INFO:tensorflow:Saving dict for global step 3000: average_loss = 0.00252507, global_step = 3000, loss = 0.0101003\n",
      "train metrics: {'average_loss': 2.6645353e-13, 'global_step': 3000, 'loss': 1.0658141e-12}\n",
      "eval metrics: {'average_loss': 0.0025250688, 'global_step': 3000, 'loss': 0.010100275}\n"
     ]
    }
   ],
   "source": [
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how our eval data has a higher loss, but it is still close to zero. That means we are learning properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
